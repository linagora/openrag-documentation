---
title: Features
---

## ✨ Key Features
This section provides a detailed explanation of the currently supported features.

The **`.hydra_config`** directory contains all the configuration files for the application. These configurations are structured using the [Hydra configuration framework](https://hydra.cc/docs/intro/). This directory will be referenced for setting up the RAG (Retrieval-Augmented Generation) pipeline.

### Supported File formats
This branch currently supports the following file types:

* **TextFiles**: `txt`, `md`
* **Document Files**: `pdf`, `docx`, `doc`, `pptx`
* **Audio Files**: `wav`, `mp3`, `mp4`, `ogg`, `flv`, `wma`, `aac`
* **Images**: `png:, jpeg, jpg, svg`

Files are converted tp **Markdown**, with images replaced by captions generated by a **Vision Language Model (VLM)**. (Refer to the **Configuration** section for additional details.) The final Markdown output is then split into chunks and indexed in the [Milvus vector database](https://milvus.io/).

> [!NOTE]
> **Upcoming Support**: Future releases will expand compatibility to include additional formats such as `csv`, `odt`, `html`, and other widely used open-source document types.

### Chunking
Multiple [chunking strategies](./.hydra_config/chunker) are supported: **`semantic`, `markdown`, and `recursive`** chunking. Files are converted to markdown and the **same chunker** is used for all types. Format-specific chunkers (e.g., for CSV, HTML) will be added later. 

```yml
# .hydra_config/chunker/markdown_splitter.yaml
defaults:
  - base
name: markdown_splitter
chunk_size: 512
chunk_overlap: 100
```

The **`chunk_size`** and **`chunk_overlap`** values are expressed in **tokens**, not characters. For enhanced retrieval, enable the **contextual retrieval** — a technique introduced by Anthropic to improve retrieval performance ([Contextual Retrieval](https://www.anthropic.com/news/contextual-retrieval)).

### Indexing
Chunks are stored in the **Milvus** vector database using the `Qwen/Qwen3-Embedding-0.6B` embedder via VLLM. To explore alternatives, check the [MTEB benchmark](https://huggingface.co/spaces/mteb/leaderboard).

> \[!IMPORTANT]
> Use an embedding model suited to your document languages and context window needs. The default model supports English and French.


### Document Retrieval & Reranking
* Search Pipeline: We use a **hybrid search** combining **semantic search** and **BM25** keyword matching for broader coverage. Results are merged and ranked with [Reciprocal Rank Fusion (RRF)](https://milvus.io/docs/reranking.md) for optimal relevance.

> \[!IMPORTANT]
> Semantic similarity doesn't always mean relevance. Rerankers help refine results and reduce hallucinations by prioritizing the most relevant documents.

* *Reranker: Documents are then reranked using the multilingual reranker **`Alibaba-NLP/gte-multilingual-reranker-base`** model from Hugging Face.
