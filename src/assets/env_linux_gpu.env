# LLM
BASE_URL=
API_KEY=
MODEL=

# VLM (Visual Language Model) you can set it to the same as LLM if your LLM supports images
VLM_BASE_URL=
VLM_API_KEY=
VLM_MODEL=

## FastAPI App (no need to change it)
# APP_PORT=8080 # this is the forwarded port
# API_NUM_WORKERS=1 # Number of uvicorn workers for the FastAPI app

## To enable API HTTP authentication via HTTPBearer
# AUTH_TOKEN=sk-openrag-1234

# SAVE_UPLOADED_FILES=true # usefull for chainlit source viewing

## Set to true, it will mount chainlit chat ui to the fastapi app (Default: true)
# WITH_CHAINLIT_UI=true

## EMBEDDER
EMBEDDER_MODEL_NAME=jinaai/jina-embeddings-v3 # or any other embedder from huggingface compatible with vllm
# EMBEDDER_BASE_URL=http://vllm:8000/v1
# EMBEDDER_API_KEY=EMPTY

# RERANKER
RERANKER_ENABLED=true
RERANKER_MODEL=Alibaba-NLP/gte-multilingual-reranker-base # or jinaai/jina-reranker-v2-base-multilingual

# Prompts
PROMPTS_DIR=../prompts/example3_en # you can change it to ../prompts/example3 for french prompts

# Ray
RAY_DEDUP_LOGS=0 # turns off ray log deduplication that appear across multiple processes
RAY_ENABLE_RECORD_ACTOR_TASK_LOGGING=1 # # to enable logs at task level in ray dashboard
RAY_task_retry_delay_ms=3000
RAY_ENABLE_UV_RUN_RUNTIME_ENV=0 # critical with the newest version of UV

# Indexer UI 
## 1. replace X.X.X.X with localhost if launching local or with your server IP
## 2. APP_PORT with your FastAPI port (8080 by default)
## 3. Base URL of the Indexer UI (required to prevent CORS issues). Replace INDEXERUI_PORT with its value
## 4. Base URL of your FastAPI backend. Used by the frondend. Replace APP_PORT with the actual port number of your FastAPI backend

VITE_INCLUDE_CREDENTIALS=false # set true if fastapi authentification is enabled
INDEXERUI_PORT=8060 # Port to expose the Indexer UI (default is 3042)
INDEXERUI_URL='http://X.X.X.X:INDEXERUI_PORT'                 
VITE_API_BASE_URL='http://X.X.X.X:APP_PORT'